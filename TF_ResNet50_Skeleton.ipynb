{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "## Loading data"
      ],
      "metadata": {
        "id": "0D85rnQ1V6jW"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd"
      ],
      "metadata": {
        "id": "sU5gXi-j-Tw1"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "import PIL\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow import keras\n",
        "from tensorflow.keras import layers\n",
        "from tensorflow.keras.models import Sequential\n",
        "from tensorflow.keras.layers import Dense, Flatten\n",
        "from tensorflow.keras.optimizers import Adam"
      ],
      "metadata": {
        "id": "m_LY3qkAHMLE"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "uc2GYRZzKyzh",
        "outputId": "314d5ccd-6740-49e1-e388-57511ac6961b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2024-11-03 01:07:21--  https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.98.207, 74.125.134.207, 142.251.107.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.98.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 68606236 (65M) [application/zip]\n",
            "Saving to: ‘/tmp/cats_and_dogs_filtered.zip’\n",
            "\n",
            "/tmp/cats_and_dogs_ 100%[===================>]  65.43M  79.2MB/s    in 0.8s    \n",
            "\n",
            "2024-11-03 01:07:22 (79.2 MB/s) - ‘/tmp/cats_and_dogs_filtered.zip’ saved [68606236/68606236]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget --no-check-certificate \\\n",
        "    https://storage.googleapis.com/mledu-datasets/cats_and_dogs_filtered.zip \\\n",
        "    -O /tmp/cats_and_dogs_filtered.zip\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "local_zip = '/tmp/cats_and_dogs_filtered.zip'\n",
        "zip_ref = zipfile.ZipFile(local_zip, 'r')\n",
        "zip_ref.extractall('/tmp')\n",
        "zip_ref.close()\n",
        "\n",
        "base_dir = '/tmp/cats_and_dogs_filtered'\n",
        "train_dir = os.path.join(base_dir, 'train')\n",
        "validation_dir = os.path.join(base_dir, 'validation')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Reading the Data into arrays"
      ],
      "metadata": {
        "id": "xgEKdtTjV8Sx"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from PIL import Image\n",
        "import numpy as np\n",
        "\n",
        "NUMBER_OF_EXAMPLES = 10\n",
        "\n",
        "x_train = []\n",
        "y_train = []\n",
        "\n",
        "cats_dir = os.path.join(train_dir + \"/cats\")\n",
        "dogs_dir = os.path.join(train_dir + \"/dogs\")\n",
        "\n",
        "\n",
        "\n",
        "i = 0\n",
        "while i < NUMBER_OF_EXAMPLES:\n",
        "  if i % 2 == 0:\n",
        "    im = Image.open(os.path.join(cats_dir, os.listdir(cats_dir)[i])).convert(\"RGB\")\n",
        "\n",
        "    #im_resized is done so that they are all of the same pixel size, they are shrunk to the same size.\n",
        "    im_resized = im.resize((150,150))\n",
        "\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(1)\n",
        "  else:\n",
        "    im = Image.open(os.path.join(dogs_dir, os.listdir(dogs_dir)[i])).convert(\"RGB\")\n",
        "\n",
        "    #im_resized is done so that they are all of the same pixel size, they are shrunk to the same size.\n",
        "    im_resized = im.resize((150,150))\n",
        "\n",
        "    x_train.append(np.array(im_resized))\n",
        "    y_train.append(0)\n",
        "  i += 1"
      ],
      "metadata": {
        "id": "QOhkfFT1K4o1"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Beginning to define the model (this is where you come in, I loaded the pretrained model for you)"
      ],
      "metadata": {
        "id": "t7R64c0tV-zh"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.optim import lr_scheduler\n",
        "import numpy as np\n",
        "import torchvision\n",
        "from torchvision import datasets, models, transforms\n",
        "import matplotlib.pyplot as plt\n",
        "import time\n",
        "import os\n",
        "import copy"
      ],
      "metadata": {
        "id": "5nNf8IB_ClpB"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "pretrained_model = tf.keras.applications.ResNet50(\n",
        "    include_top=False,\n",
        "    input_shape=(150, 150, 3),\n",
        "    pooling='avg',\n",
        "    classes=2,\n",
        "    weights='imagenet'\n",
        ")"
      ],
      "metadata": {
        "id": "7zGbGnknK6uG",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3d711aa7-9e25-487d-ade6-daf0add694b6"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
            "\u001b[1m94765736/94765736\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 0us/step\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# from tensorflow.keras.layers import Resizing\n",
        "\n",
        "\n",
        "# # Add a resizing layer at the beginning of your model\n",
        "# resnet_model = Sequential([\n",
        "#    Resizing(180, 180, interpolation='bilinear', input_shape=(150, 150, 3)),\n",
        "#    pretrained_model,\n",
        "#    Flatten(),\n",
        "#    Dense(512, activation='relu'),\n",
        "#    Dense(2, activation='softmax')\n",
        "# ])\n"
      ],
      "metadata": {
        "id": "lxJraneahkcf"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model = Sequential()\n",
        "\n",
        "# for layer in pretrained_model.layers:\n",
        "#         layer.trainable=False\n",
        "\n",
        "resnet_model.add(pretrained_model)\n",
        "resnet_model.add(Flatten())\n",
        "resnet_model.add(Dense(64, activation='relu'))\n",
        "resnet_model.add(Dense(5, activation='softmax'))"
      ],
      "metadata": {
        "id": "nccKVTXGIeoy"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# resnet_model.compile(optimizer=Adam(learning_rate=0.001),loss='categorical_crossentropy',metrics=['accuracy'])\n",
        "resnet_model.compile(optimizer='adam',\n",
        "  loss='sparse_categorical_crossentropy',\n",
        "  metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "vPbSGY6fIpmX"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Convert to NumPy arrays\n",
        "x_train = np.array(x_train)\n",
        "y_train = np.array(y_train)\n",
        "\n",
        "epochs=5\n",
        "# Train the model\n",
        "resnet_model.fit(x_train, y_train, epochs=5)\n",
        "# history = resnet_model.fit(\n",
        "#     x_train,            # Training data\n",
        "#     y_train,            # Training labels\n",
        "#     epochs=epochs,      # Number of epochs\n",
        "# )"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7GcquUC1LDu6",
        "outputId": "0d2110d7-ac9b-4f89-b956-26e5885791a0"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m57s\u001b[0m 57s/step - accuracy: 0.3000 - loss: 1.6817\n",
            "Epoch 2/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 0.0310\n",
            "Epoch 3/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 7.5130e-04\n",
            "Epoch 4/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 6s/step - accuracy: 1.0000 - loss: 6.1682e-04\n",
            "Epoch 5/5\n",
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 1.0000 - loss: 4.7099e-04\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.src.callbacks.history.History at 0x7e6199bdc790>"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "resnet_model.evaluate(x_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gbTO0bysk3la",
        "outputId": "344ca9fb-302f-4f50-a040-341ffd577bce"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\u001b[1m1/1\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 4s/step - accuracy: 0.8000 - loss: 1.6556\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[1.6556284427642822, 0.800000011920929]"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# epochs=10\n",
        "# history = resnet_model.fit(\n",
        "#   train_dir,\n",
        "#   validation_data=validation_dir,\n",
        "#   epochs=epochs\n",
        "# )\n",
        "\n",
        "# # Train the model\n",
        "# history = resnet_model.fit(\n",
        "#     train_dir,\n",
        "#     validation_data=validation_dir,\n",
        "#     epochs=epochs\n",
        "# )"
      ],
      "metadata": {
        "id": "ut6NXQ7NI5iW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# model = models.resnet18(pretrained=True)\n",
        "\n",
        "# for param in model.parameters():\n",
        "#     param.requires_grad = False\n",
        "\n",
        "# num_ftrs = model.fc.in_features\n",
        "# model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "\n",
        "# model = models.resnet18(pretrained=True)\n",
        "# num_ftrs = model.fc.in_features\n",
        "\n",
        "# # Here the size of each output sample is set to 2.\n",
        "# # Alternatively, it can be generalized to nn.Linear(num_ftrs, len(class_names)).\n",
        "# model.fc = nn.Linear(num_ftrs, 2)\n",
        "\n",
        "# device = torch.device('cpu')\n",
        "# #device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "# model = model.to(device)\n",
        "\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "# # Observe that all parameters are being optimized\n",
        "# optimizer = optim.SGD(model.parameters(), lr=0.001)\n",
        "\n",
        "\n",
        "# step_lr_scheduler = lr_scheduler.StepLR(optimizer, step_size=7, gamma=0.1)\n",
        "# model = train_model(model, criterion, optimizer, step_lr_scheduler, num_epochs=25)"
      ],
      "metadata": {
        "id": "pe_SWPzQC5d7"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}